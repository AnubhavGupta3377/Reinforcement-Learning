{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5XWotx6wj2R"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9VM4vA2wlw-"
   },
   "outputs": [],
   "source": [
    "### Markov Decision Process for Small Gridworld\n",
    "# 1) State-space -> self.states\n",
    "# 2) Action-space -> self.actions\n",
    "# 3) State transition probabilities -> self.P\n",
    "# 4) Reward function -> self.rewards\n",
    "\n",
    "SHAPE = (4,4)\n",
    "UP, DOWN, LEFT, RIGHT = 0, 1, 2, 3\n",
    "\n",
    "# Helper function to convert state index from 2d to 1d\n",
    "def get_state_idx_1d(x,y,shape):\n",
    "    return x*shape[1]+y\n",
    "\n",
    "class Gridworld:\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        num_states = np.prod(shape)\n",
    "        num_actions = 4\n",
    "        self.states = np.arange(num_states)\n",
    "        self.actions = [UP,DOWN,LEFT,RIGHT]\n",
    "        self.gamma = 1\n",
    "        rewards = [-1 for j in range(num_states)]\n",
    "        rewards[0] = rewards[num_states-1] = 0\n",
    "        self.rewards = rewards\n",
    "        \n",
    "        P = np.zeros((num_states,num_actions,num_states,2)) # for each state-action pair ((x,y), a) => stores P((x',y')) and expected reward\n",
    "        states = np.arange(num_states).reshape(shape)\n",
    "        iterator = np.nditer(states, flags=['multi_index'])\n",
    "\n",
    "        # Probability of next state\n",
    "        def get_next_state(x,y,a):\n",
    "            if (x==0 and y==0) or (x==shape[0]-1 and y==shape[1]-1):\n",
    "                return get_state_idx_1d(x,y,shape)\n",
    "            nx = x\n",
    "            ny = y\n",
    "            if a == UP:\n",
    "                nx = x-1\n",
    "            elif a == DOWN:\n",
    "                nx = x+1\n",
    "            elif a == LEFT:\n",
    "                ny = y-1\n",
    "            else:\n",
    "                 ny = y+1\n",
    "            if nx < 0 or nx > shape[0]-1:\n",
    "                nx = x\n",
    "            if ny < 0 or ny > shape[1]-1:\n",
    "                ny = y\n",
    "            return get_state_idx_1d(nx, ny, shape)\n",
    "\n",
    "        while not iterator.finished:\n",
    "            x,y = iterator.multi_index\n",
    "            cur_state = get_state_idx_1d(x,y,shape)\n",
    "            for a in {UP,DOWN,LEFT,RIGHT}:\n",
    "                next_state = get_next_state(x,y,a)\n",
    "                P[cur_state][a][next_state][0] = 1\n",
    "                P[cur_state][a][next_state][1] = rewards[cur_state]\n",
    "            iterator.iternext()\n",
    "\n",
    "        self.P = P\n",
    "\n",
    "gridworld = Gridworld(SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1gJiwDoxyxu"
   },
   "outputs": [],
   "source": [
    "# Policy Evaluation Algorithm\n",
    "\n",
    "def get_value_grid(values):\n",
    "    n = len(values[0])\n",
    "    dim = int(n**0.5)\n",
    "    return np.round(values,2).reshape((dim,dim))\n",
    "\n",
    "def policy_evaluation(policy, gridworld, threshold=1e-5):\n",
    "    states = gridworld.states\n",
    "    actions = gridworld.actions\n",
    "    gamma = gridworld.gamma\n",
    "    n = len(states)\n",
    "    \n",
    "    values = np.random.random((1,n))\n",
    "    values[0][0] = values[0][n-1] = 0\n",
    "    iter_num = 0\n",
    "    print_iter = 0\n",
    "\n",
    "    print(\"Initial Value Function:\\n{}\\n\".format(get_value_grid(values)))\n",
    "    \n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in states:\n",
    "            prev_val = values[0][s]\n",
    "            temp = 0\n",
    "            for a in actions:\n",
    "                transition_prob = gridworld.P[s,a,:,0]\n",
    "                reward_fun = gridworld.P[s,a,:,1]\n",
    "                temp += policy[s][a] * np.multiply(transition_prob,(reward_fun + gamma*values)).sum()\n",
    "            values[0][s] = temp\n",
    "            delta = max(delta, abs(values[0][s] - prev_val))\n",
    "        if delta < threshold:\n",
    "            break\n",
    "        \n",
    "        if iter_num == 0 or iter_num == 2**print_iter:\n",
    "            print(\"Iteration {}\".format(iter_num))\n",
    "            print(\"Current Value Function:\\n{}\\n\".format(get_value_grid(values)))\n",
    "            print_iter += 1\n",
    "        iter_num += 1\n",
    "\n",
    "    print(\"Final Value Function:\\n{}\\n\".format(get_value_grid(values)))\n",
    "    print (\"Converged in {} iterations.\".format(iter_num))\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZRzpNeKILTWp",
    "outputId": "c6a95ec7-56eb-4b7d-866d-b8d3b6427cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Value Function:\n",
      "[[0.   0.13 0.68 0.48]\n",
      " [0.06 0.25 0.66 0.96]\n",
      " [0.8  0.73 0.72 0.58]\n",
      " [0.34 0.23 0.45 0.  ]]\n",
      "\n",
      "Iteration 0\n",
      "Current Value Function:\n",
      "[[ 0.   -0.74 -0.73 -0.7 ]\n",
      " [-0.72 -1.02 -1.02 -1.05]\n",
      " [-0.71 -1.19 -1.29 -1.44]\n",
      " [-0.95 -1.36 -1.55  0.  ]]\n",
      "\n",
      "Iteration 2\n",
      "Current Value Function:\n",
      "[[ 0.   -2.5  -3.33 -3.6 ]\n",
      " [-2.52 -3.62 -4.22 -4.37]\n",
      " [-3.44 -4.3  -4.57 -3.95]\n",
      " [-3.79 -4.5  -4.    0.  ]]\n",
      "\n",
      "Iteration 4\n",
      "Current Value Function:\n",
      "[[ 0.   -4.2  -5.87 -6.43]\n",
      " [-4.24 -5.92 -6.83 -6.97]\n",
      " [-5.96 -6.88 -6.87 -5.68]\n",
      " [-6.55 -7.04 -5.71  0.  ]]\n",
      "\n",
      "Iteration 8\n",
      "Current Value Function:\n",
      "[[  0.    -7.06 -10.02 -11.01]\n",
      " [ -7.08  -9.49 -10.75 -10.85]\n",
      " [-10.05 -10.77 -10.2   -8.17]\n",
      " [-11.06 -10.88  -8.18   0.  ]]\n",
      "\n",
      "Iteration 16\n",
      "Current Value Function:\n",
      "[[  0.   -10.56 -15.05 -16.55]\n",
      " [-10.56 -13.78 -15.41 -15.46]\n",
      " [-15.05 -15.41 -14.13 -11.11]\n",
      " [-16.56 -15.47 -11.11   0.  ]]\n",
      "\n",
      "Iteration 32\n",
      "Current Value Function:\n",
      "[[  0.   -13.15 -18.78 -20.66]\n",
      " [-13.15 -16.96 -18.87 -18.88]\n",
      " [-18.78 -18.87 -17.05 -13.29]\n",
      " [-20.66 -18.88 -13.29   0.  ]]\n",
      "\n",
      "Iteration 64\n",
      "Current Value Function:\n",
      "[[  0.   -13.95 -19.93 -21.92]\n",
      " [-13.95 -17.94 -19.93 -19.93]\n",
      " [-19.93 -19.93 -17.94 -13.96]\n",
      " [-21.92 -19.93 -13.96   0.  ]]\n",
      "\n",
      "Iteration 128\n",
      "Current Value Function:\n",
      "[[  0. -14. -20. -22.]\n",
      " [-14. -18. -20. -20.]\n",
      " [-20. -20. -18. -14.]\n",
      " [-22. -20. -14.   0.]]\n",
      "\n",
      "Final Value Function:\n",
      "[[  0. -14. -20. -22.]\n",
      " [-14. -18. -20. -20.]\n",
      " [-20. -20. -18. -14.]\n",
      " [-22. -20. -14.   0.]]\n",
      "\n",
      "Converged in 140 iterations.\n"
     ]
    }
   ],
   "source": [
    "states = gridworld.states\n",
    "actions = gridworld.actions\n",
    "policy = np.zeros((len(states),len(actions)))+0.25\n",
    "\n",
    "values = policy_evaluation(policy, gridworld, threshold=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8Y5HEnLobd1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Gridworld Policy_Evaluation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
