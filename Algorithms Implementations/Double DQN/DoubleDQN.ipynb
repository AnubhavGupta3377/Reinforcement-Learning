{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "du-B3NfH5i5C"
   },
   "source": [
    "# Double Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzpYRM2m5vUk"
   },
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:54:13.261744Z",
     "start_time": "2020-12-24T05:54:11.835930Z"
    },
    "id": "PdJIjZju5r6b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from random import randrange\n",
    "import sys\n",
    "import psutil\n",
    "import tqdm\n",
    "from collections import deque, namedtuple\n",
    "from PIL import Image\n",
    "from IPython import display as IPdisplay\n",
    "from skimage.transform import resize\n",
    "import imageio\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import gym\n",
    "from gym import logger as gymlogger\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "gymlogger.set_level(40) #error only\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqfeKFMK6MWR"
   },
   "source": [
    "#### Environment, Constants and Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:50:12.585634Z",
     "start_time": "2020-12-24T05:50:12.159103Z"
    },
    "id": "HrP59epOoY2u",
    "outputId": "23408637-16e1-4f4d-b97f-a43d29fd23c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0, 255, (210, 160, 3), uint8)\n",
      "Discrete(4)\n",
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT']\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"BreakoutDeterministic-v4\").env\n",
    "#env = gym.make(\"Pong-v4\").env\n",
    "\n",
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "print(env.get_action_meanings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:50:12.605067Z",
     "start_time": "2020-12-24T05:50:12.588424Z"
    },
    "id": "tz1rK3nfIt7J"
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAIN = False\n",
    "TEST_MODULES = False # Whether to run test cases for individual modules\n",
    "INPUT_SHAPE = env.observation_space.shape # (210,160,3) For Atari Games\n",
    "PREPROCESSED_STATE_SHAPE = (84,84)\n",
    "NUM_ACTIONS = env.action_space.n\n",
    "EXP_DIR = \"Breakout\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        gamma: Discount Factor\n",
    "        target_update_every: Copy weights from online network to target\n",
    "                             network after this many (time) steps\n",
    "        num_episodes: Maximum number of episodes to train\n",
    "        max_steps: Maximum number of times to train\n",
    "        epsilon_start: Initial epsilon for epsilon-greedy policy\n",
    "        epsilon_end: Mininum value epsilon can go to\n",
    "        num_steps_epsilon_decay: Use epsilon decay for this many steps\n",
    "        batch_size: Batch size to sample from replay memory\n",
    "        repeat_action: Number of frames to repeat the last action\n",
    "        model_save_freq: Save the model and replay memory to disk after this many episodes\n",
    "        \"\"\"\n",
    "        self.gamma = 0.99\n",
    "        self.replay_memory_size = 600_000\n",
    "        self.min_replay_memory_size = 50_000\n",
    "        self.target_update_every = 10_000\n",
    "        self.num_episodes = 20_000\n",
    "        self.max_steps = 20_000_000\n",
    "        self.epsilon_start = 1.0\n",
    "        self.epsilon_end_1 = 0.1\n",
    "        self.epsilon_end_2 = 0.03\n",
    "        self.num_steps_epsilon_decay_1 = 6_000_000\n",
    "        self.num_steps_epsilon_decay_2 = 25_000_000\n",
    "        self.batch_size = 32\n",
    "        self.repeat_action = 4\n",
    "        self.model_save_freq = 2000 # Episodes\n",
    "        self.max_episode_length = 20000\n",
    "\n",
    "if not os.path.exists(EXP_DIR):\n",
    "    os.makedirs(EXP_DIR)\n",
    "if not os.path.exists(os.path.join(EXP_DIR, 'models')):\n",
    "    os.makedirs(os.path.join(EXP_DIR, 'models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgTCw-Vsypf_"
   },
   "source": [
    "#### Preprocess Atari Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:50:12.738573Z",
     "start_time": "2020-12-24T05:50:12.611017Z"
    },
    "id": "Pg08EUznys29"
   },
   "outputs": [],
   "source": [
    "def preprocess(frame):\n",
    "    state = frame[30:195, :, :] # For Breakout\n",
    "    #state = frame[30:190, 10:150, :] # For Pong\n",
    "    state = cv2.cvtColor(state, cv2.COLOR_RGB2GRAY)\n",
    "    state = cv2.resize(state, PREPROCESSED_STATE_SHAPE, interpolation = cv2.INTER_AREA)\n",
    "    return np.expand_dims(state, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:50:12.850130Z",
     "start_time": "2020-12-24T05:50:12.741184Z"
    },
    "id": "XZWWw6kIE1cR",
    "outputId": "e0086385-0a4a-4b52-de2d-e1e587c7c456"
   },
   "outputs": [],
   "source": [
    "def test_preprocessing():\n",
    "    frame = env.reset()\n",
    "    preprocessed_image = preprocess(frame)\n",
    "    assert preprocessed_image.shape==(1,84,84), \"Preprocessed image not of desired size\"\n",
    "    print(\"Test: OK\")\n",
    "\n",
    "if TEST_MODULES:\n",
    "    test_preprocessing()\n",
    "    \n",
    "    # Visualize one preprocessed frame\n",
    "    frame = env.reset()\n",
    "    plt.imshow(preprocess(frame).reshape((84,84)), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmqliBbIOtu1"
   },
   "source": [
    "#### Estimator Network\n",
    "- This network is used by both online network and target network\n",
    "- Both networks have different weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:50:12.933286Z",
     "start_time": "2020-12-24T05:50:12.853431Z"
    },
    "id": "mYHMFwJ4iptS"
   },
   "outputs": [],
   "source": [
    "class EstimatorNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network used by online network and target network \n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super(EstimatorNetwork, self).__init__()\n",
    "        self.env = env\n",
    "        num_actions = env.action_space.n\n",
    "\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=8, stride=4)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight, nonlinearity='relu')\n",
    "        nn.init.constant_(self.conv1.bias, 0)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight, nonlinearity='relu')\n",
    "        nn.init.constant_(self.conv2.bias, 0)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        nn.init.kaiming_normal_(self.conv3.weight, nonlinearity='relu')\n",
    "        nn.init.constant_(self.conv3.bias, 0)\n",
    "        \n",
    "        self.linear1 = nn.Linear(3136, 512)\n",
    "        nn.init.kaiming_normal_(self.linear1.weight, nonlinearity='relu')\n",
    "\n",
    "        self.linear2 = nn.Linear(512, num_actions)\n",
    "        nn.init.kaiming_normal_(self.linear2.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        linear1_out = self.linear1(x)\n",
    "        return self.linear2(linear1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:50:13.022432Z",
     "start_time": "2020-12-24T05:50:12.937412Z"
    },
    "id": "9IGyWtBWN3HO",
    "outputId": "f30606d5-aad0-4d3a-ae3a-97f8af13b2cd"
   },
   "outputs": [],
   "source": [
    "# Test that the network actually learns\n",
    "def test_estimator_network():\n",
    "    estimator = EstimatorNetwork(env).to(DEVICE)\n",
    "    frame = env.reset()\n",
    "    observation = preprocess(frame)\n",
    "    observation = np.vstack([observation] * 4)\n",
    "    observations = np.array([observation] * 2)\n",
    "    observations = torch.from_numpy(observations / 255.0).to(DEVICE).float()\n",
    "\n",
    "    y = torch.tensor([[10.0,10.0,10.0,10.0],[10.0,10.0,10.0,10.0]], device=DEVICE)\n",
    "    optimizer = torch.optim.Adam(estimator.parameters(), lr=0.01)\n",
    "    for i in range(300):\n",
    "        predictions = estimator(observations)\n",
    "        loss = F.smooth_l1_loss(predictions, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    new_preds = estimator(observations)\n",
    "    assert max(new_preds[0]) < 11 and min(new_preds[0]) > 9, \"Test failed for update\"\n",
    "    assert max(new_preds[1]) < 11 and min(new_preds[1]) > 9, \"Test failed for update\"\n",
    "    print(\"Test2: OK\")\n",
    "\n",
    "if TEST_MODULES: test_estimator_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09qbJ-Nk2XQL"
   },
   "source": [
    "#### Replay Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:50:13.132821Z",
     "start_time": "2020-12-24T05:50:13.026576Z"
    },
    "id": "A8KqmPAR2a1x"
   },
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    def __init__(self, capacity, min_size, frame_width, frame_height):\n",
    "        self.capacity = capacity\n",
    "        self.min_size = min_size\n",
    "        self.frame_width = frame_width\n",
    "        self.frame_height = frame_height\n",
    "        self.tail = 0\n",
    "        self.size = 0\n",
    "        self.frames = np.empty((capacity, frame_width, frame_height), dtype=np.uint8)\n",
    "        self.actions = np.empty(capacity, dtype=np.int32)\n",
    "        self.rewards = np.empty(capacity, dtype=np.float32)\n",
    "        self.terminal_flags = np.empty(capacity, dtype=np.bool)\n",
    "\n",
    "    def add_experience(self, frame, action, reward, done):\n",
    "        self.frames[self.tail,...] = frame.reshape((self.frame_width, self.frame_height))\n",
    "        self.actions[self.tail] = action\n",
    "        self.rewards[self.tail] = reward\n",
    "        self.terminal_flags[self.tail] = done\n",
    "        self.tail = (self.tail+1) % self.capacity\n",
    "        self.size = min(self.size+1, self.capacity)\n",
    "\n",
    "    def get_state(self, index, prev_frames):\n",
    "        \"\"\"\n",
    "        Get states stacking frames ending at index\n",
    "\n",
    "        Args:\n",
    "            index: index for which to obtain the state\n",
    "        \"\"\"\n",
    "        return self.frames[index-prev_frames+1:index+1,...]\n",
    "\n",
    "    def get_valid_index(self, prev_frames):\n",
    "        \"\"\"\n",
    "        Returns a valid index from the replay memory. A valid index is one which doesn't terminate here.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            index = randrange(prev_frames, self.size)\n",
    "            if index >= self.tail and index-prev_frames < self.tail:\n",
    "                continue\n",
    "            if self.terminal_flags[index-prev_frames:index].any():\n",
    "                continue\n",
    "            break\n",
    "        return index\n",
    "\n",
    "    def get_sample(self, batch_size, prev_frames=4):\n",
    "        states = np.empty((batch_size, prev_frames, self.frame_width, self.frame_height), dtype=np.uint8)\n",
    "        next_states = np.empty((batch_size, prev_frames, self.frame_width, self.frame_height), dtype=np.uint8)\n",
    "        indices = np.empty((batch_size,), dtype=np.int32)\n",
    "        for i in range(batch_size):\n",
    "            index = self.get_valid_index(prev_frames)\n",
    "            indices[i] = index\n",
    "            states[i,...] = self.get_state(index-1, prev_frames)\n",
    "            next_states[i,...] = self.get_state(index, prev_frames)\n",
    "        return states, self.actions[indices], self.rewards[indices], next_states, self.terminal_flags[indices]\n",
    "\n",
    "    def filled_minimum(self):\n",
    "        return self.size >= self.min_size\n",
    "\n",
    "    def save_to_disk(self, filename, save_size=200000):\n",
    "        save_size = min(save_size, self.size)\n",
    "        if self.tail > save_size:\n",
    "            replay_checkpoint = {'tail': save_size,\n",
    "                                 'size': save_size,\n",
    "                                 'frames': self.frames[self.tail-save_size+1:self.tail,...],\n",
    "                                 'actions': self.actions[self.tail-save_size+1:self.tail],\n",
    "                                 'rewards': self.rewards[self.tail-save_size+1:self.tail],\n",
    "                                 'terminal_flags': self.terminal_flags[self.tail-save_size+1:self.tail]}\n",
    "        else:\n",
    "            save_indices = list(range(self.size+self.tail-save_size-1, self.size))\n",
    "            save_indices += list(range(self.tail))\n",
    "            replay_checkpoint = {'tail': save_size,\n",
    "                                 'size': save_size,\n",
    "                                 'frames': self.frames[save_indices,...],\n",
    "                                 'actions': self.actions[save_indices],\n",
    "                                 'rewards': self.rewards[save_indices],\n",
    "                                 'terminal_flags': self.terminal_flags[save_indices]}\n",
    "        torch.save(replay_checkpoint, filename)\n",
    "\n",
    "    def load_from_disk(self, filename):\n",
    "        replay_checkpoint = torch.load(filename)\n",
    "        self.tail = replay_checkpoint['tail']\n",
    "        self.size = replay_checkpoint['size']\n",
    "        save_len = len(replay_checkpoint['frames'])\n",
    "        self.frames[:save_len,...] = replay_checkpoint['frames']\n",
    "        self.actions[:save_len] = replay_checkpoint['actions']\n",
    "        self.rewards[:save_len] = replay_checkpoint['rewards']\n",
    "        self.terminal_flags[:save_len] = replay_checkpoint['terminal_flags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVtedR8SO45Z"
   },
   "source": [
    "#### DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:50:13.251049Z",
     "start_time": "2020-12-24T05:50:13.135623Z"
    },
    "id": "_xTRVMUT_QFT"
   },
   "outputs": [],
   "source": [
    "def get_epsilon_greedy_policy(estimator):\n",
    "    \"\"\"\n",
    "    Make an epsilon-greedy policy from given Q-values\n",
    "    Returns:\n",
    "        policy: epsilon-greedy policy which takes random action with\n",
    "                probability epsilon/num_actions, otherwise takes\n",
    "                greedy action\n",
    "    \"\"\"\n",
    "    def policy(state, epsilon):\n",
    "        with torch.no_grad():\n",
    "            q_values = estimator(state)\n",
    "        num_actions = q_values.size(1)\n",
    "        greedy_action = torch.argmax(q_values).item()\n",
    "        action_probs = np.ones((num_actions)) * (epsilon/num_actions)\n",
    "        action_probs[greedy_action] += 1-epsilon\n",
    "        return action_probs\n",
    "    \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:50:13.350894Z",
     "start_time": "2020-12-24T05:50:13.253055Z"
    },
    "id": "853mlm5DoefU"
   },
   "outputs": [],
   "source": [
    "class DoubleDQNAgent:\n",
    "    def __init__(self, env, replay_memory_size, min_replay_memory_size):\n",
    "        \"\"\"\n",
    "        Initialize the deep Q-learning agent. Main components of DQN include\n",
    "        - two estimator networks\n",
    "            1. Online network\n",
    "            2. Target network\n",
    "        - replay memory\n",
    "\n",
    "        Args:\n",
    "            replay_memory_size: Size of replay memory\n",
    "            min_replay_memory_size: Minimum size of replay memory\n",
    "        \"\"\"\n",
    "\n",
    "        # DQN components\n",
    "        self.env = env\n",
    "        self.online_network = EstimatorNetwork(env).to(DEVICE)\n",
    "        self.target_network = EstimatorNetwork(env).to(DEVICE)\n",
    "        self.replay_memory = ReplayMemory(capacity=replay_memory_size,\n",
    "                                          min_size=min_replay_memory_size,\n",
    "                                          frame_width=PREPROCESSED_STATE_SHAPE[0],\n",
    "                                          frame_height=PREPROCESSED_STATE_SHAPE[1])\n",
    "        self.copy_network_weights()\n",
    "        self.target_network.eval()\n",
    "\n",
    "        # Optimizer to be used for training\n",
    "        self.optimizer = torch.optim.Adam(self.online_network.parameters(), lr=0.00001)\n",
    "        self.loss = torch.nn.SmoothL1Loss()\n",
    "\n",
    "    def copy_network_weights(self):\n",
    "        self.target_network.load_state_dict(self.online_network.state_dict())\n",
    "\n",
    "    def create_checkpoint(self, episode, stats):\n",
    "        model_dir = os.path.join(EXP_DIR, \"models\")\n",
    "        model_filename = os.path.join(model_dir, \"model_{}.pt\".format(episode))\n",
    "        optimizer_filename = os.path.join(model_dir, \"optimizer_{}.pt\".format(episode))\n",
    "        stats_filename = os.path.join(EXP_DIR, \"stats_{}.pt\".format(episode))\n",
    "        replay_filename = os.path.join(EXP_DIR, \"replay_{}.pt\".format(episode))\n",
    "        try:\n",
    "            torch.save(self.online_network.state_dict(), model_filename)\n",
    "            torch.save(self.optimizer.state_dict(), optimizer_filename)\n",
    "            torch.save(stats, stats_filename)\n",
    "            self.replay_memory.save_to_disk(replay_filename)\n",
    "            print(\"\\nCheckpoint created for episode {}\".format(episode))\n",
    "        except:\n",
    "            print (\"\\nCouldn't create checkpoint.\")\n",
    "\n",
    "    def load_checkpoint(self, episode):\n",
    "        model_dir = os.path.join(EXP_DIR, \"models\")\n",
    "        model_filename = os.path.join(model_dir, \"model_{}.pt\".format(episode))\n",
    "        optimizer_filename = os.path.join(model_dir, \"optimizer_{}.pt\".format(episode))\n",
    "        stats_filename = os.path.join(EXP_DIR, \"stats_{}.pt\".format(episode))\n",
    "        replay_filename = os.path.join(EXP_DIR, \"replay_{}.pt\".format(episode))\n",
    "        try:\n",
    "            self.online_network.load_state_dict(torch.load(model_filename, map_location=DEVICE))\n",
    "            self.optimizer.load_state_dict(torch.load(optimizer_filename, map_location=DEVICE))\n",
    "            stats = torch.load(stats_filename)\n",
    "            self.replay_memory.load_from_disk(replay_filename)\n",
    "            print(\"\\nCheckpoint loaded for episode {}\".format(episode))\n",
    "        except:\n",
    "            print (\"\\nCouldn't load checkpoint.\")\n",
    "            return 0\n",
    "        self.copy_network_weights()\n",
    "        return stats['total_steps']+1\n",
    "\n",
    "    def train(self, config, load_from_checkpoint=False, last_episode=0):\n",
    "        \"\"\"\n",
    "        Trains the DQN Agent\n",
    "\n",
    "        Args:\n",
    "            config: Training configurations\n",
    "            load_from_checkpoint: Whether to load model from checkpoint\n",
    "            last_episode: Number of episodes the agent was already trained on.\n",
    "                          Used for checkpoint name and initialize model weights\n",
    "        \"\"\"\n",
    "\n",
    "        Transition = namedtuple(\"Transition\", [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        \n",
    "        policy = get_epsilon_greedy_policy(self.target_network)\n",
    "        total_steps = 0\n",
    "\n",
    "        if load_from_checkpoint:\n",
    "            total_steps = self.load_checkpoint(last_episode)\n",
    "\n",
    "        stats = {'starting_episode': last_episode+1,\n",
    "                 'epsilon': [],\n",
    "                 'episode_lengths': [],\n",
    "                 'episode_rewards': [],\n",
    "                 'total_steps': total_steps}\n",
    "\n",
    "        replay_memory_populated = False\n",
    "        if self.replay_memory.filled_minimum():\n",
    "            replay_memory_populated = True\n",
    "        else:\n",
    "            print(\"\\nFilling up replay memory...\")\n",
    "        \n",
    "        episode_reward = 0\n",
    "        episode_length = 0\n",
    "        recent_rewards = deque(maxlen=100)\n",
    "        epsilon = config.epsilon_start\n",
    "        for episode_num in range(last_episode+1, config.num_episodes+1):\n",
    "            recent_mean_score = np.round(np.mean(recent_rewards), 2) if len(recent_rewards) > 0 else -float('inf')\n",
    "            recent_max_score = np.max(recent_rewards) if len(recent_rewards) > 0 else -float('inf')\n",
    "            \n",
    "            print(f\"\\rEpisode: {episode_num:>5}/{config.num_episodes}  Steps: {total_steps:>10}  \"\n",
    "                  f\"Epsilon: {round(epsilon, 3):>6}  Score: {episode_reward:>6}  Recent avg: {recent_mean_score:>6}  \"\n",
    "                  f\"Recent max: {recent_max_score:>6}\", end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            if episode_num % 100 == 0:\n",
    "                print()\n",
    "            \n",
    "            episode_reward = 0\n",
    "            episode_length = 0\n",
    "\n",
    "            frame = self.env.reset()\n",
    "            observation = preprocess(frame)\n",
    "            state = np.vstack([observation] * 4)\n",
    "\n",
    "            while True: # Until eipsode finishes\n",
    "                if total_steps < config.num_steps_epsilon_decay_1:\n",
    "                    epsilon = config.epsilon_end_1 + (config.epsilon_start - config.epsilon_end_1) * math.exp(-1. * total_steps / 1_000_000)\n",
    "                else:\n",
    "                    epsilon_end_1 = config.epsilon_end_1 + (config.epsilon_start - config.epsilon_end_1) * math.exp(-1. * config.num_steps_epsilon_decay_1 / 1_000_000)\n",
    "                    epsilon = epsilon_end_1 - ((epsilon_end_1 - config.epsilon_end_2) * (total_steps - config.num_steps_epsilon_decay_1) / (config.num_steps_epsilon_decay_2 - config.num_steps_epsilon_decay_1))\n",
    "                if total_steps > config.num_steps_epsilon_decay_2:\n",
    "                    epsilon = config.epsilon_end_2\n",
    "                \n",
    "                # Choose and take action based on above policy\n",
    "                action_probs = policy(torch.from_numpy(state / 255.0).float().to(DEVICE).unsqueeze(0), epsilon)\n",
    "                action = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
    "\n",
    "                # Take (repeat_action) steps into the environment (One hack to speed up training involved)\n",
    "                lives_before = self.env.ale.lives()\n",
    "                next_frame, reward, done, info = self.env.step(action)\n",
    "                observation = preprocess(next_frame)\n",
    "                lives_after = self.env.ale.lives()\n",
    "                # Losing life terminates the episode\n",
    "                replay_done = done if lives_before <= lives_after else True\n",
    "\n",
    "                # Update replay memory\n",
    "                self.replay_memory.add_experience(observation,action,reward,replay_done)\n",
    "                state = np.append(state[1:,:,:], observation, axis=0)\n",
    "\n",
    "                # Move onto next step if replay memory not filled with minimum experience\n",
    "                # No training happens in this case\n",
    "                if not self.replay_memory.filled_minimum():\n",
    "                    if done: break\n",
    "                    continue\n",
    "\n",
    "                # Training starts now\n",
    "                if not replay_memory_populated:\n",
    "                    print(\"\\nReplay memory filled with minimum experience.\")\n",
    "                    replay_memory_populated = True\n",
    "                    break\n",
    "\n",
    "                total_steps += 1\n",
    "                \n",
    "                # Update Stats\n",
    "                episode_reward += reward\n",
    "                episode_length += 1\n",
    "\n",
    "                # Copy weights from online network to target network after some time\n",
    "                if total_steps % config.target_update_every == 0:\n",
    "                    self.copy_network_weights()\n",
    "\n",
    "                if total_steps % config.repeat_action != 0:\n",
    "                    if done: break\n",
    "                    continue\n",
    "\n",
    "                # Sample a random batch of experiences from replay memory\n",
    "                states_batch, actions_batch, rewards_batch, next_states_batch, done_batch = self.replay_memory.get_sample(config.batch_size, prev_frames=4)\n",
    "                states_batch = torch.from_numpy(states_batch/255.0).float().to(DEVICE)\n",
    "                actions_batch = torch.from_numpy(actions_batch).to(DEVICE)\n",
    "                rewards_batch = torch.from_numpy(rewards_batch).to(DEVICE)\n",
    "                next_states_batch = torch.from_numpy(next_states_batch/255.0).float().to(DEVICE)\n",
    "                done_batch = torch.from_numpy(done_batch).to(DEVICE)\n",
    "\n",
    "                #################################### Double DQN ######################################\n",
    "                batch_size = states_batch.size(0)\n",
    "                \n",
    "                # Get q_values of greedy targets for this batch\n",
    "                with torch.no_grad():\n",
    "                    next_q_values = self.online_network(next_states_batch)\n",
    "                best_actions = torch.max(next_q_values, 1)[1]\n",
    "                best_action_indices = torch.arange(config.batch_size, device=DEVICE) * next_q_values.size(1) + best_actions\n",
    "                with torch.no_grad():\n",
    "                    next_q_values_target = self.target_network(next_states_batch)\n",
    "                targets_batch = rewards_batch + (~done_batch) * config.gamma *\\\n",
    "                                torch.gather(next_q_values_target.view(-1), 0, best_action_indices)\n",
    "\n",
    "                predictions = self.online_network(states_batch)\n",
    "\n",
    "                # Get the q_values of only current actions taken from states\n",
    "                action_indices = torch.arange(config.batch_size, device=DEVICE) * predictions.size(1) + actions_batch\n",
    "                action_predictions = torch.gather(predictions.view(-1), 0, action_indices)\n",
    "                #####################################################################################\n",
    "\n",
    "                # Compute loss and optimize model\n",
    "                loss = self.loss(targets_batch, action_predictions)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                for param in self.online_network.parameters():\n",
    "                    param.grad.data.clamp_(-1, 1)\n",
    "                self.optimizer.step()\n",
    "\n",
    "                if done or episode_length > config.max_episode_length: break\n",
    "\n",
    "            if replay_memory_populated and episode_length > 0:\n",
    "                # Update stats\n",
    "                stats['epsilon'].append(epsilon)\n",
    "                stats['episode_rewards'].append(episode_reward)\n",
    "                stats['episode_lengths'].append(episode_length)\n",
    "                stats['total_steps'] = total_steps\n",
    "                recent_rewards.append(episode_reward)\n",
    "\n",
    "            if episode_num % config.model_save_freq == 0 or total_steps >= config.max_steps or episode_num == config.num_episodes:\n",
    "                self.create_checkpoint(4, stats)\n",
    "            if total_steps >= config.max_steps:\n",
    "                break\n",
    "\n",
    "        print(\"\\nFinished\\n\")\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96FMwZTgubf6"
   },
   "source": [
    "#### Start training the agent\n",
    "Now, it's time to actually run the agent and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:50:13.463699Z",
     "start_time": "2020-12-24T05:50:13.353175Z"
    },
    "id": "R8NKznBCLB2_",
    "outputId": "73a28d1d-437c-415e-d158-b6fa52dbbc4a"
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    config = Config()\n",
    "    agent = DoubleDQNAgent(env, config.replay_memory_size, config.min_replay_memory_size)\n",
    "\n",
    "    stats = agent.train(config=config,\n",
    "                       load_from_checkpoint=True,\n",
    "                       last_episode=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9Ci_h2VKYfr"
   },
   "source": [
    "## Let's check the training results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3-h2RloyRhF"
   },
   "source": [
    "### Training Losses and Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:50:13.707718Z",
     "start_time": "2020-12-24T05:50:13.466421Z"
    },
    "id": "0bifmf-xfQ2X"
   },
   "outputs": [],
   "source": [
    "all_rewards = []\n",
    "load_stats_from_file = True # Set this to true if want to load training statistics from files\n",
    "\n",
    "if load_stats_from_file:\n",
    "    last_episodes = [1,2,3,4] # Update this list with every new run end episode\n",
    "    for episode in last_episodes:\n",
    "        stats_file = os.path.join(EXP_DIR, \"stats/stats_{}.pt\".format(episode))\n",
    "        stats = torch.load(stats_file)\n",
    "        all_rewards += stats[\"episode_rewards\"]\n",
    "else:\n",
    "    all_rewards += stats[\"episode_rewards\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:50:13.965275Z",
     "start_time": "2020-12-24T05:50:13.710912Z"
    },
    "id": "VGJ-w10Dy5wc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_stats(rewards):\n",
    "    rewards = pd.Series(all_rewards).rolling(200).mean()\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "\n",
    "    ax1.plot(rewards)\n",
    "    ax1.set_title(\"Episode returns over time (smoothing window = 200 episodes)\")\n",
    "    ax1.set_xlabel(\"Episode\")\n",
    "    ax1.set_ylabel(\"Total Episode Score\")\n",
    "\n",
    "plot_stats(all_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see the agent's behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:50:13.984912Z",
     "start_time": "2020-12-24T05:50:13.967934Z"
    },
    "code_folding": [
     16
    ]
   },
   "outputs": [],
   "source": [
    "def generate_gif(frame_number, frames_for_gif, reward, path):\n",
    "    for idx, frame_idx in enumerate(frames_for_gif): \n",
    "        frames_for_gif[idx] = frame_idx.astype(np.uint8)\n",
    "    imageio.mimsave(path, frames_for_gif, duration=1/30)\n",
    "    \n",
    "def display_gif(path):\n",
    "    return IPdisplay.HTML('<img src=\"{}\">'.format(path))\n",
    "\n",
    "def run_episode(env, policy, epsilon, save_path=None):\n",
    "    frames_for_gif = []\n",
    "    state = env.reset()\n",
    "    frames_for_gif.append(state)\n",
    "    state = preprocess(state)\n",
    "    state = np.vstack([state] * 4)\n",
    "    final_score = 0\n",
    "    t = 0\n",
    "    while t < 20000:\n",
    "        action_probs = policy(torch.from_numpy(state / 255.0).float().to(DEVICE).unsqueeze(0), epsilon)\n",
    "        action = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
    "        action_reward = 0\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        frames_for_gif.append(np.transpose(next_state, axes=[0,1,2]))\n",
    "        next_state = preprocess(next_state)\n",
    "        next_state = np.append(state[1:,:,:], next_state, axis=0)\n",
    "        final_score += reward\n",
    "        state = next_state\n",
    "        t += 1\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t))\n",
    "            print(\"Final Score: {}\".format(int(final_score)))\n",
    "            break\n",
    "    if save_path:\n",
    "        generate_gif(t, frames_for_gif, final_score, \n",
    "                     os.path.join(save_path, f\"episode_{t}_score_{final_score}.gif\"))\n",
    "        return os.path.join(save_path, f\"episode_{t}_score_{final_score}.gif\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:50:24.488385Z",
     "start_time": "2020-12-24T05:50:13.987746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1555 timesteps\n",
      "Final Score: 263\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"Breakout/videos/episode_1555_score_263.0.gif\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_name = \"model_25m_steps.pt\"\n",
    "checkpoint_name = os.path.join(os.path.join(EXP_DIR, f\"models/{checkpoint_name}\"))\n",
    "\n",
    "online_network = EstimatorNetwork(env).to(DEVICE)\n",
    "online_network.load_state_dict(torch.load(checkpoint_name, map_location=torch.device(DEVICE)))\n",
    "online_network.eval()\n",
    "policy = get_epsilon_greedy_policy(online_network)\n",
    "\n",
    "epsilon = 0.01\n",
    "saved_path = run_episode(env, policy, epsilon, os.path.join(EXP_DIR, \"videos\"))\n",
    "display_gif(saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
